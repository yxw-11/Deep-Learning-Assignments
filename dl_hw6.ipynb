{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DeepLearning_Spring2021_HW6_for_students.ipynb","provenance":[{"file_id":"1WhKIcswOFDaiyzDkJZEx_mZZdOS0LDcg","timestamp":1602791335771}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZQCz6Qbn8Xi3"},"source":["\n","# Deep Learning Homework 6 (Spring 2021)\n","\n","This code is provided for Deep Learning class (CS 482/682) Homework 6. For ease of implementation, we recommend working entire in Google Colaboratory.\n","\n","@Copyright Cong Gao, the Johns Hopkins University, cgao11@jhu.edu. Modifications made by Hongtao Wu, Suzanna Sia, Hao Ding, and Keith Harrigian.\n"]},{"cell_type":"markdown","metadata":{"id":"AGA2oroEWDk1"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"WyxXeYArKAIh"},"source":["## Mount Google Drive Data (If using Google Colaboratory)\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/gdrive')\n","except:\n","    print(\"Mounting Failed.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"diX3FqyIWDk2"},"source":["## Standard Library\n","import os\n","import json\n","\n","## External Libraries\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torchvision import transforms\n","from torch.autograd import Variable\n","import torch.nn.functional as functional\n","from torch.utils.data import Dataset, DataLoader\n","from skimage import io\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Byv0ZVSoWDk2"},"source":["# Problem 1: Unsupervised Pre-training"]},{"cell_type":"markdown","metadata":{"id":"x4NCcExeWDk2"},"source":["### Training Hyperparameters\n","\n","These are recommended hyperparameters - please feel free to use what works for you. Batch size can be changed if it does not match your memory, please state your batch step_size in your report."]},{"cell_type":"code","metadata":{"id":"sl_S6MdMWDk2"},"source":["## Batch Size\n","train_batch_size = 10\n","validation_batch_size = 10\n","\n","## Learning Rate\n","learning_rate = 0.001\n","\n","# Epochs (Consider setting high and implementing early stopping)\n","num_epochs = 200"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m3BRbLhNWDk3"},"source":["### Data Paths"]},{"cell_type":"code","metadata":{"id":"aGfa8qhNWDk3"},"source":["# General Data Directory ##TODO: Please fill in the appropriate directory\n","data_dir = \"./HW6_data/\"\n","\n","## Segmentation + Colorization Paths\n","segmentation_data_dir = f\"{data_dir}/segmentation/\"\n","colorization_data_dir = f\"{data_dir}/colorization/\"\n","\n","# Mask JSON\n","mask_json = f\"{data_dir}/mapping.json\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gpAXntx2WDk3"},"source":["### Data Loaders\n","\n","We have provided you with some preprocessing code for the images but you should feel free to modify the class however you please to support your training schema. In the very least, you will have to modify the dataloader to support loading of the colorization dataset."]},{"cell_type":"code","metadata":{"id":"gL-hqHd1WDk4"},"source":["## Image Transforms\n","img_transform = transforms.Compose([\n","        transforms.ToTensor(),\n","])\n","\n","## Image Dataloader\n","class ImageDataset(Dataset):\n","    \n","    \"\"\"\n","    ImageDataset\n","    \"\"\"\n","    \n","    def __init__(self,\n","                 input_dir,\n","                 op,\n","                 mask_json_path,\n","                 transforms=None):\n","        \"\"\"\n","        ##TODO: Add support for colorization dataset\n","        \n","        Args:\n","            input_dir (str): Path to either colorization or segmentation directory\n","            op (str): One of \"train\", \"val\", or \"test\" signifying the desired split\n","            mask_json_path (str): Path to mapping.json file\n","            transforms (list or None): Image transformations to apply upon loading.\n","        \"\"\"\n","        self.transform = transforms\n","        self.op = op\n","        with open(mask_json_path, 'r') as f:\n","            self.mask = json.load(f)\n","        self.mask_num = len(self.mask)  # There are 6 categories: grey, dark grey, and black\n","        self.mask_value = [value for value in self.mask.values()]\n","        self.mask_value.sort()\n","        try:\n","            if self.op == 'train':\n","                self.data_dir = os.path.join(input_dir, 'train')\n","            elif self.op == 'val':\n","                self.data_dir = os.path.join(input_dir, 'validation')\n","            elif self.op == 'test':\n","                self.data_dir = os.path.join(input_dir, 'test')\n","        except ValueError:\n","            print('op should be either train, val or test!')\n","\n","    def __len__(self):\n","        \"\"\"\n","        \n","        \"\"\"\n","        return len(next(os.walk(self.data_dir))[1])\n","\n","    def __getitem__(self,\n","                    idx):\n","        \"\"\"\n","        \n","        \"\"\"\n","        ## Load Image and Parse Properties\n","        img_name = str(idx) + '_input.jpg'\n","        mask_name = str(idx) + '_mask.png'\n","        img = io.imread(os.path.join(self.data_dir, str(idx), img_name))\n","        mask = io.imread(os.path.join(self.data_dir, str(idx), mask_name))\n","        if len(mask.shape) == 2:\n","            h, w  = mask.shape\n","        elif len(mask.shape) == 3:\n","            h, w, c = mask.shape\n","        ## Convert grey-scale label to one-hot encoding\n","        new_mask = np.zeros((h, w, self.mask_num))\n","        for idx in range(self.mask_num):\n","            #if the mask has 3 dimension use this code\n","            new_mask[:, :, idx] = mask[:,:,0] == self.mask_value[idx]\n","            #if the mask has 1 dimension use the code below\n","            #new_mask[:, :, idx] = mask == self.mask_value[idx]\n","        ## Transform image and mask\n","        if self.transform:\n","            img, mask = self.img_transform(img, new_mask)\n","        # ## Use dictionary to output\n","        # sample = {'img': img, 'mask': mask}\n","        # return sample\n","        return img, mask\n","\n","    def img_transform(self,\n","                      img,\n","                      mask):\n","        \"\"\"\n","        \n","        \"\"\"\n","        ## Apply Transformations to Image and Mask\n","        img = self.transform(img)\n","        mask = self.transform(mask)\n","        return img, mask"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OhdKw8V_WDk5"},"source":["## Model Architecture\n","\n","Finish building the U-net architecture below."]},{"cell_type":"code","metadata":{"id":"ZM98wgQim9Dj"},"source":["## Functions for adding the convolution layer\n","def add_conv_stage(dim_in,\n","                   dim_out,\n","                   kernel_size=3,\n","                   stride=1,\n","                   padding=1,\n","                   bias=True,\n","                   useBN=True):\n","    \"\"\"\n","    \n","    \"\"\"\n","    # Use batch normalization\n","    if useBN:\n","        return nn.Sequential(\n","          nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n","          nn.BatchNorm2d(dim_out),\n","          nn.LeakyReLU(0.1),\n","          nn.Conv2d(dim_out, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n","          nn.BatchNorm2d(dim_out),\n","          nn.LeakyReLU(0.1)\n","        )\n","    # No batch normalization\n","    else:\n","        return nn.Sequential(\n","          nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n","          nn.ReLU(),\n","          nn.Conv2d(dim_out, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n","          nn.ReLU()\n","        )\n","\n","## Upsampling\n","def upsample(ch_coarse,\n","             ch_fine):\n","    \"\"\"\n","    \n","    \"\"\"\n","    return nn.Sequential(\n","                    nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False),\n","                    nn.ReLU())\n","\n","\n","# U-Net\n","class UNET(nn.Module):\n","    \n","    \"\"\"\n","    \n","    \"\"\"\n","    def __init__(self,n_classes, useBN=True):\n","        \"\"\"\n","        Args:\n","            useBN (bool): Turn Batch Norm on or off\n","        \"\"\"\n","        super(UNET, self).__init__()\n","        # Downgrade stages\n","        self.conv1 = add_conv_stage(3, 32, useBN=useBN)\n","        self.conv2 = add_conv_stage(32, 64, useBN=useBN)\n","        self.conv3 = add_conv_stage(64, 128, useBN=useBN)\n","        self.conv4 = add_conv_stage(128, 256, useBN=useBN)\n","        # Upgrade stages\n","        self.conv3m = add_conv_stage(256, 128, useBN=useBN)\n","        self.conv2m = add_conv_stage(128,  64, useBN=useBN)\n","        self.conv1m = add_conv_stage( 64,  32, useBN=useBN)\n","        # Maxpool\n","        self.max_pool = nn.MaxPool2d(2)\n","        # Upsample layers\n","        self.upsample43 = upsample(256, 128)\n","        self.upsample32 = upsample(128,  64)\n","        self.upsample21 = upsample(64 ,  32)\n","        # weight initialization\n","        # You can have your own weight intialization. This is just an example.\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","        #TODO: Design your last layer & activations\n","\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass\n","        \"\"\"\n","        conv1_out = self.conv1(x)\n","        conv2_out = self.conv2(self.max_pool(conv1_out))\n","        conv3_out = self.conv3(self.max_pool(conv2_out))\n","        conv4_out = self.conv4(self.max_pool(conv3_out))\n","\n","        conv4m_out_ = torch.cat((self.upsample43(conv4_out), conv3_out), 1)\n","        conv3m_out  = self.conv3m(conv4m_out_)\n","\n","        conv3m_out_ = torch.cat((self.upsample32(conv3m_out), conv2_out), 1)\n","        conv2m_out  = self.conv2m(conv3m_out_)\n","\n","        conv2m_out_ = torch.cat((self.upsample21(conv2m_out), conv1_out), 1)\n","        conv1m_out  = self.conv1m(conv2m_out_)\n","\n","        #TODO: Design your last layer & activations\n","\n","        return \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zn8qJ5y7WDk9"},"source":["### DICE Score and DICE Loss\n","\n","Finish implementing the DICE score function below and then write a Dice Loss function that you can use to update your model weights."]},{"cell_type":"code","metadata":{"id":"w4JGCHGrnctJ"},"source":["##TODO: Finish implementing the multi-class DICE score function\n","def dice_score_image(prediction, target, n_classes):\n","    '''\n","      computer the mean dice score for a single image\n","\n","      Reminders: A false positive is a result that indicates a given condition exists, when it does not\n","               A false negative is a test result that indicates that a condition does not hold, while in fact it does\n","      Args:\n","          prediction (tensor): predictied labels of the image\n","          target (tensor): ground truth of the image\n","          n_classes (int): number of classes\n","    \n","      Returns:\n","          m_dice (float): Mean dice score over classes\n","    '''\n","    ## Should test image one by one\n","    assert img.shape[0] == 1 #This line can not be deleted\n","    ## TODO: Compute Dice Score for Each Class. Compute Mean Dice Score over Classes.\n","    dice_classes = np.zeros(n_classes)\n","    for cl in range(num_classes):\n","        TP = \n","        FP = \n","        FN = \n","        #When there is no grount truth of the class in this image\n","        #Give 1 dice score if False Positive pixel number is 0, \n","        #give 0 dice score if False Positive pixel number is not 0 (> 0).\n","        dice_classes[cl] = \n","    return dice_classes.mean()\n","\n","\n","\n","def dice_score_dataset(model, dataloader, num_classes, use_gpu=False):\n","    \"\"\"\n","    Compute the mean dice score on a set of data.\n","    \n","    Note that multiclass dice score can be defined as the mean over classes of binary\n","    dice score. Dice score is computed per image. Mean dice score over the dataset is the dice\n","    score averaged across all images.\n","    \n","    Reminders: A false positive is a result that indicates a given condition exists, when it does not\n","               A false negative is a test result that indicates that a condition does not hold, while in fact it does\n","     \n","    Args:\n","        model (UNET class): Your trained model\n","        dataloader (DataLoader): Dataset for evaluation\n","        num_classes (int): Number of classes\n","    \n","    Returns:\n","        m_dice (float): Mean dice score over the input dataset\n","    \"\"\"\n","    ## Number of Batches and Cache over Dataset \n","    n_batches = len(dataloader)\n","    scores = np.zeros(n_batches)\n","    ## Evaluate\n","    model.eval()\n","    idx = 0\n","    for data in datalaoader:\n","        ## Format Data\n","        img, target = data\n","        if use_gpu:\n","            img = img.cuda()\n","            target = target.cuda()\n","        ## Make Predictions\n","        out = model(img)\n","        n_classes = out.shape[1]\n","        prediction = torch.argmax(out, dim = 1)\n","        scores[idx] = dice_score_image(prediction, target, n_classes)\n","        idx += 1\n","    ## Average Dice Score Over Images\n","    m_dice = scores.mean()\n","    return m_dice\n","\n","\n","## TODO: Implement DICE loss, \n","#  It should conform to to how we computer the dice score.\n","class DICELoss(nn.Module):\n","    def __init__(self, *):\n","    \n","    def forward(self, *):\n","        return *"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L5iVvONAWDlB"},"source":["## Training Procedure (Segmentation)"]},{"cell_type":"code","metadata":{"id":"Jm_FUG4C0wTl"},"source":["## Initialize your unet\n","model = UNET(n_classes)\n","\n","## Initialize Dataloaders\n","train_dataset=ImageDataset(input_dir=segmentation_data_dir, op=\"train\", mask_json_path=mask_json, transforms=img_transform)\n","validation_dataset=ImageDataset(input_dir=segmentation_data_dir, op=\"val\", mask_json_path=mask_json, transforms=img_transform)\n","test_dataset=ImageDataset(input_dir=segmentation_data_dir, op=\"val\", mask_json_path=mask_json, transforms=img_transform)\n","train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n","validation_dataloader = DataLoader(validation_dataset, batch_size=validation_batch_size, shuffle=False)\n","test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","## Initialize Optimizer and Learning Rate Scheduler\n","optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n","\n","print(\"Start Training...\")\n","for epoch in range(num_epochs):\n","    ########################### Training #####################################\n","    print(\"\\nEPOCH \" +str(epoch+1)+\" of \"+str(num_epochs)+\"\\n\")\n","    # TODO: Design your own training section\n","\n","\n","    ########################### Validation #####################################\n","    # TODO: Design your own validation section"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XX67pCavWDlC"},"source":["## Training Procedure: Colorization Pre-training\n","\n","Complete the rest of this problem in the cells below."]},{"cell_type":"code","metadata":{"id":"geo-2XNCWDlD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q72LlQ0cWDlD"},"source":["# Problem 2: Transfer Learning"]},{"cell_type":"markdown","metadata":{"id":"7dkMWrcyWDlD"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"R9MnzH2mWDlD"},"source":["## Import VGG and FashionMNIST\n","from torchvision.models import vgg16\n","from torchvision.datasets import FashionMNIST"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LNP3HoCMWDlD"},"source":["### Data Loading"]},{"cell_type":"code","metadata":{"id":"7NYpDsdPWDlE"},"source":["## Specify Batch Size\n","train_batch_size = 32\n","test_batch_size = 32\n","\n","## Specify Image Transforms\n","img_transform = transforms.Compose([\n","    transforms.Resize((224,224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","## Download Datasets\n","train_data = FashionMNIST('./data', transform=img_transform, download=True, train=True)\n","test_data = FashionMNIST('./data', transform=img_transform, download=True, train=False)\n","\n","## Initialize Dataloaders\n","training_dataloader = DataLoader(train_data, batch_size=train_batch_size, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rq_5k9rCWDlE"},"source":["### Model Initialization and Training/Fine-tuning\n","\n","Complete the rest of the assignment in the notebook below."]},{"cell_type":"code","metadata":{"id":"0nD75TosWDlE"},"source":[""],"execution_count":null,"outputs":[]}]}